{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (2024.12.0)\n",
      "Requirement already satisfied: langchain-text-splitters in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (0.3.4)\n",
      "Requirement already satisfied: tiktoken in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (0.8.0)\n",
      "Requirement already satisfied: openai in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (1.58.1)\n",
      "Requirement already satisfied: python-dotenv in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (1.26.4)\n",
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp311-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: neo4j-graphrag in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from langchain-text-splitters) (0.3.28)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from tiktoken) (2.32.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from openai) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: networkx in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: json-repair<0.31.0,>=0.30.2 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from neo4j-graphrag) (0.30.3)\n",
      "Requirement already satisfied: neo4j<6.0.0,>=5.17.0 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from neo4j-graphrag) (5.27.0)\n",
      "Requirement already satisfied: types-pyyaml<7.0.0.0,>=6.0.12.20240917 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from neo4j-graphrag) (6.0.12.20241221)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.26->langchain-text-splitters) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.26->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.26->langchain-text-splitters) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.26->langchain-text-splitters) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.26->langchain-text-splitters) (8.5.0)\n",
      "Requirement already satisfied: pytz in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from neo4j<6.0.0,>=5.17.0->neo4j-graphrag) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.26->langchain-text-splitters) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/denizaskin/CodeBase/agenticchunking/.venv/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.26->langchain-text-splitters) (1.0.0)\n",
      "Using cached torch-2.5.1-cp311-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, MarkupSafe, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.16.1 jinja2-3.1.5 mpmath-1.3.0 sympy-1.13.1 torch-2.5.1\n"
     ]
    }
   ],
   "source": [
    "## Code from https://github.com/neo4j-product-examples/graphrag-python-examples/tree/main\n",
    "\n",
    "!pip install fsspec langchain-text-splitters tiktoken openai python-dotenv numpy torch neo4j-graphrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load neo4j credentials (and openai api key in background).\n",
    "load_dotenv('.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "\n",
    "#uncomment this line if you aren't using a .env file\n",
    "# os.environ['OPENAI_API_KEY'] = 'copy_paste_the_openai_key_here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo4j\n",
    "from neo4j_graphrag.llm import OpenAILLM\n",
    "from neo4j_graphrag.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "driver = neo4j.GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "ex_llm=OpenAILLM(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    model_params={\n",
    "        \"response_format\": {\"type\": \"json_object\"}, # use json_object formatting for best results\n",
    "        \"temperature\": 0 # turning temperature down for more deterministic results\n",
    "    }\n",
    ")\n",
    "\n",
    "#create text embedder\n",
    "embedder = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "You are a medical researcher tasked with extracting information from papers \n",
    "and structuring it in a property graph to inform further medical and research Q&A.\n",
    "\n",
    "Extract the entities (nodes) and specify their type from the following Input text.\n",
    "Also extract the relationships between these nodes. the relationship direction goes from the start node to the end node. \n",
    "\n",
    "\n",
    "Return result as JSON using the following format:\n",
    "{{\"nodes\": [ {{\"id\": \"0\", \"label\": \"the type of entity\", \"properties\": {{\"name\": \"name of entity\" }} }}],\n",
    "  \"relationships\": [{{\"type\": \"TYPE_OF_RELATIONSHIP\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"details\": \"Description of the relationship\"}} }}] }}\n",
    "\n",
    "- Use only the information from the Input text.  Do not add any additional information.  \n",
    "- If the input text is empty, return empty Json. \n",
    "- Make sure to create as many nodes and relationships as needed to offer rich medical context for further research.\n",
    "- An AI knowledge assistant must be able to read this graph and immediately understand the context to inform detailed research questions. \n",
    "- Multiple documents will be ingested from different sources and we are using this property graph to connect information, so make sure entity types are fairly general. \n",
    "\n",
    "Use only fhe following nodes and relationships (if provided):\n",
    "{schema}\n",
    "\n",
    "Assign a unique ID (string) to each node, and reuse it to define relationships.\n",
    "Do respect the source and target node types for relationship and\n",
    "the relationship direction.\n",
    "\n",
    "Do not return any additional information other than the JSON in it.\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Input text:\n",
    "\n",
    "{text}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import FixedSizeSplitter\n",
    "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
    "\n",
    "kg_builder_pdf = SimpleKGPipeline(\n",
    "    llm=ex_llm,\n",
    "    driver=driver,\n",
    "    text_splitter=FixedSizeSplitter(chunk_size=500, chunk_overlap=100),\n",
    "    embedder=embedder,\n",
    "    # entities=node_labels,\n",
    "    # relations=rel_types,\n",
    "    prompt_template=prompt_template,\n",
    "    from_pdf=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: __Entity__)} {position: line: 1, column: 15, offset: 14} for query: 'MATCH (entity:__Entity__)  RETURN count(entity) as c'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: run_id='05dfe5bf-7b02-4a47-84d5-bac526012dcf' result={'resolver': {'number_of_nodes_to_resolve': 0, 'number_of_created_nodes': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: __Entity__)} {position: line: 1, column: 15, offset: 14} for query: 'MATCH (entity:__Entity__)  RETURN count(entity) as c'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: run_id='2b863d91-dac2-4213-adb9-8f6bc43371c5' result={'resolver': {'number_of_nodes_to_resolve': 0, 'number_of_created_nodes': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: __Entity__)} {position: line: 1, column: 15, offset: 14} for query: 'MATCH (entity:__Entity__)  RETURN count(entity) as c'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: run_id='1b1feea3-8613-4681-849a-3bb399cbc7b9' result={'resolver': {'number_of_nodes_to_resolve': 0, 'number_of_created_nodes': None}}\n"
     ]
    }
   ],
   "source": [
    "# Read the transcripts into strings\n",
    "with open(\"datasets/transcripts/mortgage_loan_1_transcript.txt\", \"r\") as f:\n",
    "    mortgage_loan_transcript_1 = ''.join(f.read().splitlines())\n",
    "\n",
    "with open(\"datasets/transcripts/mortgage_loan_2_transcript.txt\", \"r\") as f:\n",
    "    mortgage_loan_transcript_2 = ''.join(f.read().splitlines())\n",
    "\n",
    "with open(\"datasets/transcripts/mortgage_loan_3_transcript.txt\", \"r\") as f:\n",
    "    mortgage_loan_transcript_3 = ''.join(f.read().splitlines())\n",
    "\n",
    "# Create a list of transcript texts\n",
    "transcripts = [\n",
    "    mortgage_loan_transcript_1,\n",
    "    mortgage_loan_transcript_2,\n",
    "    mortgage_loan_transcript_3,\n",
    "]\n",
    "\n",
    "# Process each transcript\n",
    "for text in transcripts:\n",
    "    pdf_result = await kg_builder_pdf.run_async(text=text)  # Pass the text directly\n",
    "    print(f\"Result: {pdf_result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
